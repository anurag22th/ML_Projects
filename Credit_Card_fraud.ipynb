{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygJJOAmTGCOp"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy\n",
        "import pandas\n",
        "import matplotlib\n",
        "import seaborn\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('creditcard.csv')"
      ],
      "metadata": {
        "id": "H8ly9aXUGL1Q",
        "outputId": "e325a23f-a4e8-4743-ed2a-08c0aa07341c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'creditcard.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-463682848ec9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'creditcard.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'creditcard.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "id": "99yO3Bx0GMoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the data\n",
        "data = data.sample(frac=0.1, random_state = 1)\n",
        "print(data.shape)\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "4mLpUqw6GR7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms of each parameter\n",
        "data.hist(figsize = (20, 20))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sLU-bnP4GXnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine number of fraud cases in dataset\n",
        "\n",
        "Fraud = data[data['Class'] == 1]\n",
        "Valid = data[data['Class'] == 0]\n",
        "\n",
        "outlier_fraction = len(Fraud)/float(len(Valid))\n",
        "print(outlier_fraction)\n",
        "\n",
        "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1])))\n",
        "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))"
      ],
      "metadata": {
        "id": "Do9Ai_ylGd3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corrmat = data.corr()\n",
        "fig = plt.figure(figsize = (12, 9))\n",
        "\n",
        "sns.heatmap(corrmat, vmax = .8, square = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gttQmJHpGiQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all columns\n",
        "columns = data.columns.tolist()\n",
        "\n",
        "# remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Class\"]]\n",
        "\n",
        "# Prediction for\n",
        "target = \"Class\"\n",
        "\n",
        "X = data[columns]\n",
        "Y = data[target]\n",
        "\n",
        "# Print shapes\n",
        "print(X.shape)\n",
        "print(Y.shape)\n"
      ],
      "metadata": {
        "id": "DR9gsJ4vGmFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# define random states\n",
        "state = 1\n",
        "\n",
        "# define outlier detection tools to be compared\n",
        "classifiers = {\n",
        "    \"Isolation Forest\": IsolationForest(max_samples=len(X),\n",
        "                                        contamination=outlier_fraction,\n",
        "                                        random_state=state),\n",
        "    \"Local Outlier Factor\": LocalOutlierFactor(\n",
        "        n_neighbors=20,\n",
        "        contamination=outlier_fraction)}"
      ],
      "metadata": {
        "id": "sqdaqUxcG2Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "plt.figure(figsize=(9, 7))\n",
        "n_outliers = len(Fraud)\n",
        "\n",
        "\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "\n",
        "    # fit the data and tag outliers\n",
        "    if clf_name == \"Local Outlier Factor\":\n",
        "        y_pred = clf.fit_predict(X)\n",
        "        scores_pred = clf.negative_outlier_factor_\n",
        "    else:\n",
        "        clf.fit(X)\n",
        "        scores_pred = clf.decision_function(X)\n",
        "        y_pred = clf.predict(X)\n",
        "\n",
        "    # Reshape the prediction values to 0 for valid, 1 for fraud.\n",
        "    y_pred[y_pred == 1] = 0\n",
        "    y_pred[y_pred == -1] = 1\n",
        "\n",
        "    n_errors = (y_pred != Y).sum()\n",
        "\n",
        "    # Run classification metrics\n",
        "    print('{}: {}'.format(clf_name, n_errors))\n",
        "    print(accuracy_score(Y, y_pred))\n",
        "    print(classification_report(Y, y_pred))"
      ],
      "metadata": {
        "id": "-wd8L9h1G5qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import gridspec"
      ],
      "metadata": {
        "id": "hLLCZuxFG52n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the csv file using pandas\n",
        "# best way is to mount the drive on colab and\n",
        "# copy the path for the csv file\n",
        "data = pd.read_csv(\"credit.csv\")\n"
      ],
      "metadata": {
        "id": "IlYzina8_4Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a peek at the data\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "iDbhIFnD_6tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the data\n",
        "# data = data.sample(frac = 0.1, random_state = 48)\n",
        "print(data.shape)\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "4zn1JdSJ_-H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Determine number of fraud cases in dataset\n",
        "fraud = data[data['Class'] == 1]\n",
        "valid = data[data['Class'] == 0]\n",
        "outlierFraction = len(fraud)/float(len(valid))\n",
        "print(outlierFraction)\n",
        "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1])))\n",
        "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))\n"
      ],
      "metadata": {
        "id": "oAKkB31f_-D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(“Amount details of the fraudulent transaction”)\n",
        "fraud.Amount.describe()\n"
      ],
      "metadata": {
        "id": "rCq1y0gV_9_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(“details of valid transaction”)\n",
        "valid.Amount.describe()\n"
      ],
      "metadata": {
        "id": "WWVoWlUU_9wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corrmat = data.corr()\n",
        "fig = plt.figure(figsize = (12, 9))\n",
        "sns.heatmap(corrmat, vmax = .8, square = True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t3-OJIk8_9jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dividing the X and the Y from the dataset\n",
        "X = data.drop(['Class'], axis = 1)\n",
        "Y = data[\"Class\"]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "# getting just the values for the sake of processing\n",
        "# (its a numpy array with no columns)\n",
        "xData = X.values\n",
        "yData = Y.values\n"
      ],
      "metadata": {
        "id": "PKx6wPFMAOXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Scikit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(\n",
        "\t\txData, yData, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "ZcfxV3CYAOSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Random Forest Classifier (RANDOM FOREST)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(xTrain, yTrain)\n",
        "# predictions\n",
        "yPred = rfc.predict(xTest)\n"
      ],
      "metadata": {
        "id": "1ldQToNtAONK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the classifier\n",
        "# printing every score of the classifier\n",
        "# scoring in anything\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "n_outliers = len(fraud)\n",
        "n_errors = (yPred != yTest).sum()\n",
        "print(\"The model used is Random Forest classifier\")\n",
        "\n",
        "acc = accuracy_score(yTest, yPred)\n",
        "print(\"The accuracy is {}\".format(acc))\n",
        "\n",
        "prec = precision_score(yTest, yPred)\n",
        "print(\"The precision is {}\".format(prec))\n",
        "\n",
        "rec = recall_score(yTest, yPred)\n",
        "print(\"The recall is {}\".format(rec))\n",
        "\n",
        "f1 = f1_score(yTest, yPred)\n",
        "print(\"The F1-Score is {}\".format(f1))\n",
        "\n",
        "MCC = matthews_corrcoef(yTest, yPred)\n",
        "print(\"The Matthews correlation coefficient is{}\".format(MCC))\n"
      ],
      "metadata": {
        "id": "8ciZk2buAN8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the confusion matrix\n",
        "LABELS = ['Normal', 'Fraud']\n",
        "conf_matrix = confusion_matrix(yTest, yPred)\n",
        "plt.figure(figsize =(12, 12))\n",
        "sns.heatmap(conf_matrix, xticklabels = LABELS,\n",
        "\t\t\tyticklabels = LABELS, annot = True, fmt =\"d\");\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6ZOLmt17AYU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}